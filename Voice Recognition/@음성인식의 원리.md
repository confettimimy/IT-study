# 음성인식의 원리

[영상 참고](https://www.youtube.com/watch?v=9h8FxFuOzIc)

​    

## 음성데이터

컴퓨터는 마이크로 들어온 소리 중에 필요한 음성만을 검출

사람의 목소리를 특정할 수 있는 주파수 대역을 뽑아냄

음성으로 판단되는 것의 변화를 음성인식으로 사용

이렇게 얻어진 **음성데이터**

​    

## 음향 모델링

음성을 초당 50회 정도로 쪼개어 음성이 변화하는 특징을 수치화하여 분석하기 쉽게 전처리

이 각각의 데이터 간의 변화

쪼개진 데이터가 어떤 음소에 매칭되는지를 만들어내는 **음향모델링** 진행

음향모델링은 딥러닝을 통해 이뤄진다.(학습데이터를 만드는 과정이 필요)

*음성 데이터의 변화가 별 음소에 매칭될 확률을 학습하는 것*  (예: 이 음성데이터 변화는 음소'ㄷ'이다 라고 학습된다) (이것은 사과이다 라고 학습시키는 것과 같이)

​    

## 언어모델

이렇게 학습된 것은 단지 음소가 나타날 높은 확률만을 조합하여 (예: ㄷ ㅣ ㅁ ㅓ)

즉 "디모" 이런식으로 매칭되어 이상한 단어로 인식될 수 있음 

이때 필요한 것이 **언어모델** -> 음성 인식결과가 문맥에 맞는 단어로 매칭될 수 있도록 함

예를 들어 음소별로 확률을 조합했을 때에는  [기본58%  기반24%  기분18%] 58%인 '기본'으로 인식되겠지만, 

"나는 ㅇㅇ이 나쁘다"라고 문장의 의미를 따지면 '기분'이라는 단어가 더 적절.

따라서 많은 문장을 언어모델로 학습할 수록 문맥을 고려하여 음성을 더욱 정확하게 인식시킬 수 있다.

​    

---

결국 음성인식의 정확성은 

기존의 인간의 음성과 문장을 많이 학습시키는 것이 관건이다.

최근 음성인식의 성능 향상은 네트워크를 통해 실시간으로 익명화된 음성데이터를 수집하고 학습할 수 있는 환경이 마련됐기 때문.

구글, 네이버, 카카오 등은 각 회사가 구축한 학습 데이터를 기반으로 인터넷을 통해 음성인식 api를 제공하기 때문에 대규모의 음성학습 과정을 진행하지 않아도 음성인식 프로그램을 굉장히 쉽게 만들 수 있다. 

